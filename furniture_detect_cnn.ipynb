{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "furniture detect cnn.ipynb",
      "mount_file_id": "10MKc8o7_7-qHYNIU6JW9ESm-OAJdQ3Ki",
      "authorship_tag": "ABX9TyNXs+6FQcA+PsfAyXrfH3NS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/THUNDERSAMA/cnn_furniture/blob/main/furniture_detect_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty3Kxsv33CMv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN-uPAUY1Aqw",
        "outputId": "507880a1-f38c-4994-c1ae-6be0ac00a900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available()else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy8uqKR84DVn",
        "outputId": "c4719c24-a70c-4ed3-f5bd-fa5b2ac4f3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path=\"/content/drive/MyDrive/img/train\"\n",
        "tr_transformer=transforms.Compose([transforms.Resize((150,150))\n",
        ",transforms.ToTensor()])\n",
        "tr_dataset=torchvision.datasets.ImageFolder(train_path,transform=tr_transformer)\n",
        "train_loader=torch.utils.data.DataLoader(dataset=tr_dataset,batch_size=12,shuffle=False)"
      ],
      "metadata": {
        "id": "8t-sAXPS1tRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_std(loader):\n",
        "    mean=0.\n",
        "    std=0.\n",
        "    total_images_count=0\n",
        "    for images,_ in loader:\n",
        "        image_count=images.size(0)\n",
        "        images=images.view(image_count,images.size(1),-1)\n",
        "        mean += images.mean(2).sum(0)\n",
        "        std += images.std(2).sum(0)\n",
        "        total_images_count += image_count\n",
        "    mean /= total_images_count\n",
        "    std /= total_images_count\n",
        "\n",
        "    return mean,std\n",
        "get_mean_std(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkTFQ8BH3pD0",
        "outputId": "6c5fb9c0-50e2-4544-a8bc-2cc55d162931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.6090, 0.5617, 0.5238]), tensor([0.2307, 0.2434, 0.2494]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer=transforms.Compose([transforms.Resize((150,150))\n",
        ",transforms.RandomHorizontalFlip(),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize([0.2307, 0.2434, 0.2494],[0.2307, 0.2434, 0.2494])\n",
        "])"
      ],
      "metadata": {
        "id": "vRHvBBKI7o5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path=\"/content/drive/MyDrive/img/train\"\n",
        "test_path=\"/content/drive/MyDrive/img/val/mix\"\n",
        "train_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=50,shuffle =True)\n",
        "test_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=50,shuffle =True\n",
        ")"
      ],
      "metadata": {
        "id": "6Vtn7-B_6iL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
      ],
      "metadata": {
        "id": "F4cSRnRjy6Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abGHaEnpzBTa",
        "outputId": "dd2fb5f6-6306-47c0-921f-fa832c7b308a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bed', 'chair', 'sofa', 'swivelchair', 'table']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=6):\n",
        "        super(ConvNet,self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "\n",
        "        self.relu1=nn.ReLU()\n",
        "\n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "\n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        self.relu2=nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        self.relu3=nn.ReLU()\n",
        "\n",
        "\n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "\n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "\n",
        "        output=self.pool(output)\n",
        "\n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "\n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        output=output.view(-1,32*75*75)\n",
        "\n",
        "\n",
        "        output=self.fc(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "4zKygxMCzJ1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ConvNet(num_classes=5).to(device)"
      ],
      "metadata": {
        "id": "mNY-JCSCz-Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "3i3Vh3QF0D7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=10\n",
        "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
        "print(train_count,test_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhqcLWIX0JrT",
        "outputId": "84571deb-8cba-4162-cbbe-95129fc494bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4024 423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    #Evaluation and training of dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "\n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if (torch.cuda.is_available()):\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "\n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "\n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    test_accuracy=0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if (torch.cuda.is_available()):\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "\n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "\n",
        "    test_accuracy=test_accuracy/test_count\n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "\n",
        "    #Saving the model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ2mrsoH0whB",
        "outputId": "ad0d463b-751d-4d03-daac-3519466ec5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Train Loss: tensor(1.7995) Train Accuracy: 0.7837972166998012 Test Accuracy: 7.612293144208038\n",
            "Epoch: 1 Train Loss: tensor(0.8233) Train Accuracy: 0.8635685884691849 Test Accuracy: 8.709219858156029\n",
            "Epoch: 2 Train Loss: tensor(0.6131) Train Accuracy: 0.8866799204771372 Test Accuracy: 8.50354609929078\n",
            "Epoch: 3 Train Loss: tensor(0.2897) Train Accuracy: 0.9259443339960238 Test Accuracy: 9.044917257683215\n",
            "Epoch: 4 Train Loss: tensor(0.2648) Train Accuracy: 0.9333996023856859 Test Accuracy: 8.6903073286052\n",
            "Epoch: 5 Train Loss: tensor(0.1636) Train Accuracy: 0.9607355864811133 Test Accuracy: 9.286052009456265\n",
            "Epoch: 6 Train Loss: tensor(0.1573) Train Accuracy: 0.9637176938369781 Test Accuracy: 9.281323877068559\n",
            "Epoch: 7 Train Loss: tensor(0.0800) Train Accuracy: 0.9781312127236581 Test Accuracy: 9.300236406619385\n",
            "Epoch: 8 Train Loss: tensor(0.1016) Train Accuracy: 0.9744035785288271 Test Accuracy: 9.361702127659575\n",
            "Epoch: 9 Train Loss: tensor(0.1429) Train Accuracy: 0.9617296222664016 Test Accuracy: 9.349881796690307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import squeezenet1_1\n",
        "import torch.functional as F\n",
        "from io import open\n",
        "import os\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "import glob\n",
        "import cv2"
      ],
      "metadata": {
        "id": "D3Rw8C0SQgDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=6):\n",
        "        super(ConvNet,self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        self.relu1=nn.ReLU()\n",
        "\n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "\n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        self.relu2=nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        self.relu3=nn.ReLU()\n",
        "\n",
        "\n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "\n",
        "        output=self.pool(output)\n",
        "\n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "\n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        output=output.view(-1,32*75*75)\n",
        "\n",
        "\n",
        "        output=self.fc(output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "zS01YyXiNLv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint=torch.load('best_checkpoint.model')\n",
        "model=ConvNet(num_classes=5)\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKpq9DAOMCXQ",
        "outputId": "376cf04a-f694-4ded-aa54-9e16005c73ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU()\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu3): ReLU()\n",
              "  (fc): Linear(in_features=180000, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
        "    transforms.Normalize([0.2307, 0.2434, 0.2494],[0.2307, 0.2434, 0.2494])\n",
        "])"
      ],
      "metadata": {
        "id": "lcAtp6A-Nb9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(img_path,transformer):\n",
        "\n",
        "    image=Image.open(img_path)\n",
        "\n",
        "    image_tensor=transformer(image).float()\n",
        "\n",
        "\n",
        "    image_tensor=image_tensor.unsqueeze_(0)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        image_tensor.cuda()\n",
        "\n",
        "    input=Variable(image_tensor)\n",
        "\n",
        "\n",
        "    output=model(input)\n",
        "\n",
        "    index=output.data.numpy().argmax()\n",
        "\n",
        "    pred=classes[index]\n",
        "\n",
        "    return pred\n"
      ],
      "metadata": {
        "id": "kLGT5XlhMHNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path=glob.glob(test_path+'/*.jpg')"
      ],
      "metadata": {
        "id": "qsmYS6qVMV7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dict={}\n",
        "\n",
        "for i in images_path:\n",
        "    pred_dict[i[i.rfind('/')+1:]]=prediction(i,transformer)"
      ],
      "metadata": {
        "id": "Vlld3mqkMZl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MozdhjtzMdnU",
        "outputId": "b743b297-7d96-4c68-af1c-85e5048e044d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'00000943.jpg': 'bed',\n",
              " '00000948.jpg': 'sofa',\n",
              " '00000945.jpg': 'bed',\n",
              " '00000947.jpg': 'bed',\n",
              " '00000944.jpg': 'bed',\n",
              " '00000949.jpg': 'bed',\n",
              " '00000942.jpg': 'bed',\n",
              " '00000946.jpg': 'bed',\n",
              " '00000047.jpg': 'bed',\n",
              " '00000048.jpg': 'swivelchair',\n",
              " '00000012.jpg': 'chair',\n",
              " '00000045.jpg': 'chair',\n",
              " '00000055.jpg': 'chair',\n",
              " '00000050.jpg': 'chair',\n",
              " '00000052.jpg': 'chair',\n",
              " '00000051.jpg': 'chair',\n",
              " '00000212.jpg': 'sofa',\n",
              " '00000206.jpg': 'sofa',\n",
              " '00000211.jpg': 'sofa',\n",
              " '00000209.jpg': 'sofa',\n",
              " '00000216.jpg': 'sofa',\n",
              " '00000214.jpg': 'sofa',\n",
              " '00000210.jpg': 'table',\n",
              " '00000213.jpg': 'sofa',\n",
              " '00000215.jpg': 'sofa',\n",
              " '00000398.jpg': 'table',\n",
              " '00000401.jpg': 'table',\n",
              " '00000399.jpg': 'table',\n",
              " '00000400.jpg': 'table',\n",
              " '00000396.jpg': 'bed',\n",
              " '00000397.jpg': 'bed',\n",
              " '00000019.jpg': 'swivelchair',\n",
              " '00000074.jpg': 'swivelchair',\n",
              " '00000077.jpg': 'swivelchair',\n",
              " '00000073.jpg': 'swivelchair',\n",
              " '00000075.jpg': 'sofa',\n",
              " '00000078.jpg': 'swivelchair',\n",
              " '00000076.jpg': 'swivelchair',\n",
              " '00000079.jpg': 'swivelchair'}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}